{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5dda1b6",
   "metadata": {},
   "source": [
    "## Stocks Income statements - ETL Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b921a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - \n",
      "\n",
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 95.0.4638\n",
      "[WDM] - Get LATEST driver version for 95.0.4638\n",
      "[WDM] - Driver [C:\\Users\\James\\.wdm\\drivers\\chromedriver\\win32\\95.0.4638.17\\chromedriver.exe] found in cache\n",
      "[WDM] - \n",
      "\n",
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 95.0.4638\n",
      "[WDM] - Get LATEST driver version for 95.0.4638\n",
      "[WDM] - Driver [C:\\Users\\James\\.wdm\\drivers\\chromedriver\\win32\\95.0.4638.17\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x23a4632cec0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import time\n",
    "from datetime import datetime\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "\n",
    "############################################################\n",
    "\n",
    "#Delete existing Database before beginning the ETL process\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "client.Stocks_db.income_statements.drop()\n",
    "\n",
    "############################################################\n",
    "\n",
    "###############  CBA  ###############\n",
    "##### Extract #####\n",
    "# Read the tables in the HTML page\n",
    "# Scrape the Data\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "stock = 'CBA'\n",
    "\n",
    "url = f'https://au.finance.yahoo.com/quote/{stock}.AX/financials?p={stock}.AX'\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "\n",
    "# Get table headers\n",
    "income_table_headers = soup.find_all('div', class_='D(tbr) C($primaryColor)')\n",
    "# Get table rows\n",
    "income_table_rows = soup.find_all('div', class_='D(tbr) fi-row Bgc($hoverBgColor):h')\n",
    "\n",
    "# Get the table headers\n",
    "table_headers_list = []\n",
    "for header in income_table_headers:\n",
    "    for span in header.find_all('span'):\n",
    "        table_headers_list.append(span.text)\n",
    "        \n",
    "# Get all the table rows\n",
    "table_rows = []\n",
    "row_list = []\n",
    "for rows in income_table_rows:\n",
    "    for fields in rows:\n",
    "        row_list.append(fields.text)\n",
    "    # Add row to table rows\n",
    "    table_rows.append(row_list)\n",
    "    # Reset the row list for the next row\n",
    "    row_list = []\n",
    "    \n",
    "# Quit the browser\n",
    "browser.quit()\n",
    "\n",
    "# Convert the result into a DataFrame\n",
    "income_statements = pd.DataFrame(table_rows, columns=table_headers_list)\n",
    "##### Extract #####\n",
    "\n",
    "##### Transform #####\n",
    "#Find empty or NaN entry in Dataframe\n",
    "missing_cols, missing_rows = (\n",
    "    (income_statements.isnull().sum(x) | income_statements.eq('').sum(x))\n",
    "    .loc[lambda x: x.gt(0)].index\n",
    "    for x in (0, 1)\n",
    ")\n",
    "income_statements.loc[missing_rows, missing_cols]\n",
    "\n",
    "# Delete row with index label '1' and set new index \n",
    "Income_statements_df = income_statements.drop([1]).set_index('Breakdown')\n",
    "# Replace all fields containing '-' with 0\n",
    "Income_statements_df = Income_statements_df.replace('-',0)\n",
    "Income_statements_df\n",
    "\n",
    "# Create Series per year\n",
    "#2017-2018\n",
    "Income_statements_df_2018 = Income_statements_df[['29/06/2018']].copy()\n",
    "#2018-2019\n",
    "Income_statements_df_2019 = Income_statements_df[['29/06/2019']].copy()\n",
    "#2019-2020\n",
    "Income_statements_df_2020 = Income_statements_df[['29/06/2020']].copy()\n",
    "#2020-2021\n",
    "Income_statements_df_2021 = Income_statements_df[['29/06/2021']].copy()\n",
    "# TTM\n",
    "Income_statements_df_ttm = Income_statements_df[['ttm']].copy()\n",
    "\n",
    "# Convert them to dictionaries\n",
    "Income_statements_2018_dict = Income_statements_df_2018.to_dict()['29/06/2018']\n",
    "Income_statements_2019_dict = Income_statements_df_2019.to_dict()['29/06/2019']\n",
    "Income_statements_2020_dict = Income_statements_df_2020.to_dict()['29/06/2020']\n",
    "Income_statements_2021_dict = Income_statements_df_2021.to_dict()['29/06/2021']\n",
    "Income_statements_ttm_dict =  Income_statements_df_ttm.to_dict()['ttm']\n",
    "##### Transform #####\n",
    "\n",
    "##### Load #####\n",
    "#Convert series into dictionaries and group it into a one report/object\n",
    "stock_income_statements={'29/06/2018':Income_statements_2018_dict,\n",
    "                              '29/06/2019':Income_statements_2019_dict,\n",
    "                               '29/06/2020':Income_statements_2020_dict,\n",
    "                              '29/06/2021':Income_statements_2021_dict,\n",
    "                                'ttm':Income_statements_ttm_dict}\n",
    "stock_reports={}\n",
    "stock_reports[stock] = stock_income_statements\n",
    "\n",
    "#Insert object into MongoDB\n",
    "client.Stocks_db.income_statements.insert_one(stock_reports)\n",
    "##### Load #####\n",
    "###############  CBA   ###############\n",
    "\n",
    "############################################################\n",
    "\n",
    "###############  ANZ   ###############\n",
    "##### Extract #####\n",
    "# Read the tables in the HTML page\n",
    "# Scrape the Data\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "stock = 'ANZ'\n",
    "\n",
    "url = f'https://au.finance.yahoo.com/quote/{stock}.AX/financials?p={stock}.AX'\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "\n",
    "# Get table headers\n",
    "income_table_headers = soup.find_all('div', class_='D(tbr) C($primaryColor)')\n",
    "# Get table rows\n",
    "income_table_rows = soup.find_all('div', class_='D(tbr) fi-row Bgc($hoverBgColor):h')\n",
    "\n",
    "# Get the table headers\n",
    "table_headers_list = []\n",
    "for header in income_table_headers:\n",
    "    for span in header.find_all('span'):\n",
    "        table_headers_list.append(span.text)\n",
    "\n",
    "# Get all the table rows\n",
    "table_rows = []\n",
    "row_list = []\n",
    "for rows in income_table_rows:\n",
    "    for fields in rows:\n",
    "        row_list.append(fields.text)\n",
    "    # Add row to table rows\n",
    "    table_rows.append(row_list)\n",
    "    # Reset the row list for the next row\n",
    "    row_list = []\n",
    "    \n",
    "# Quit the browser\n",
    "browser.quit()\n",
    "\n",
    "# Convert the result into a DataFrame\n",
    "income_statements = pd.DataFrame(table_rows, columns=table_headers_list)\n",
    "##### Extract #####\n",
    "\n",
    "##### Transform #####\n",
    "#Find empty or NaN entry in Dataframe\n",
    "missing_cols, missing_rows = (\n",
    "    (income_statements.isnull().sum(x) | income_statements.eq('').sum(x))\n",
    "    .loc[lambda x: x.gt(0)].index\n",
    "    for x in (0, 1)\n",
    ")\n",
    "income_statements.loc[missing_rows, missing_cols]\n",
    "\n",
    "# Delete row with index label '1' and set new index \n",
    "Income_statements_df = income_statements.drop([1]).set_index('Breakdown')\n",
    "\n",
    "# Replace all fields containing '-' with 0\n",
    "Income_statements_df = Income_statements_df.replace('-',0)\n",
    "\n",
    "#Create Dataframe/Series per year\n",
    "#2017-2018\n",
    "Income_statements_df_2018 = Income_statements_df[['29/09/2018']].copy()\n",
    "#2018-2019\n",
    "Income_statements_df_2019 = Income_statements_df[['29/09/2019']].copy()\n",
    "#2019-2020\n",
    "Income_statements_df_2020 = Income_statements_df[['29/09/2020']].copy()\n",
    "# TTM\n",
    "Income_statements_df_ttm = Income_statements_df[['ttm']].copy()\n",
    "\n",
    "# Convert series to dictionaries\n",
    "Income_statements_2018_dict = Income_statements_df_2018.to_dict()['29/09/2018']\n",
    "Income_statements_2019_dict = Income_statements_df_2019.to_dict()['29/09/2019']\n",
    "Income_statements_2020_dict = Income_statements_df_2020.to_dict()['29/09/2020']\n",
    "Income_statements_ttm_dict = Income_statements_df_ttm.to_dict()['ttm']\n",
    "##### Transform #####\n",
    "\n",
    "##### Load #####\n",
    "# The default port used by MongoDB is 27017\n",
    "# https://docs.mongodb.com/manual/reference/default-mongodb-port/\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "#Convert dataframe into dict and group it into a one report/object\n",
    "stock_income_statements = {'29/09/2018': Income_statements_2018_dict,\n",
    "                              '29/09/2019': Income_statements_2019_dict,\n",
    "                               '29/09/2020': Income_statements_2020_dict,\n",
    "                                'ttm': Income_statements_ttm_dict}\n",
    "stock_reports = {}\n",
    "stock_reports[stock] = stock_income_statements\n",
    "\n",
    "#Insert object into MongoDB\n",
    "client.Stocks_db.income_statements.insert_one(stock_reports)\n",
    "##### Load #####\n",
    "###############  ANZ   ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf71477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
